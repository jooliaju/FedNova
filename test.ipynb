{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c3612a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428e8f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import math\n",
    "from math import ceil\n",
    "from random import Random\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data.distributed\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import Process\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "\n",
    "from distoptim import FedProx, FedNova\n",
    "import util_v4 as util\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# import matplotlib.pyplot as plt\\\n",
    "import plotly.express as px\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import List, Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821ace7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='CIFAR-10 baseline')\n",
    "parser.add_argument('--name','-n', \n",
    "                    default=\"default\", \n",
    "                    type=str, \n",
    "                    help='experiment name, used for saving results')\n",
    "parser.add_argument('--backend',\n",
    "                    default=\"nccl\",\n",
    "                    type=str,\n",
    "                    help='background name')\n",
    "parser.add_argument('--model', \n",
    "                    default=\"VGG\", #default: res\n",
    "                    type=str, \n",
    "                    help='neural network model')\n",
    "parser.add_argument('--alpha', \n",
    "                    default=0.2, \n",
    "                    type=float, \n",
    "                    help='control the non-iidness of dataset')\n",
    "parser.add_argument('--gmf', \n",
    "                    default=0, \n",
    "                    type=float, \n",
    "                    help='global (server) momentum factor')\n",
    "parser.add_argument('--lr', \n",
    "                    default=0.1, \n",
    "                    type=float, \n",
    "                    help='client learning rate')\n",
    "parser.add_argument('--momentum', \n",
    "                    default=0.0, \n",
    "                    type=float, \n",
    "                    help='local (client) momentum factor')\n",
    "parser.add_argument('--bs', \n",
    "                    default=32, \n",
    "                    type=int, \n",
    "                    help='batch size on each worker/client')\n",
    "parser.add_argument('--rounds', \n",
    "                    default=4, \n",
    "                    type=int, \n",
    "                    help='total coommunication rounds')\n",
    "parser.add_argument('--localE', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='number of local epochs')\n",
    "parser.add_argument('--print_freq', \n",
    "                    default=100, \n",
    "                    type=int, \n",
    "                    help='print info frequency')\n",
    "parser.add_argument('--size', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='number of local workers')\n",
    "parser.add_argument('--rank', \n",
    "                    default=0, \n",
    "                    type=int, \n",
    "                    help='the rank of worker')\n",
    "parser.add_argument('--seed', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='random seed')\n",
    "parser.add_argument('--save', '-s', \n",
    "                    default=True, \n",
    "                    action='store_true', \n",
    "                    help='whether save the training results')\n",
    "parser.add_argument('--p', '-p', \n",
    "                    action='store_true', \n",
    "                    help='whether the dataset is partitioned or not')\n",
    "parser.add_argument('--NIID',\n",
    "                    \n",
    "                    action='store_true',\n",
    "                    help='whether the dataset is non-iid or not')\n",
    "parser.add_argument('--pattern',\n",
    "                    default='constant',\n",
    "                    type=str, \n",
    "                    help='pattern of local steps')\n",
    "parser.add_argument('--optimizer', \n",
    "                    default='fednova',  ##default is 'local'\n",
    "                    type=str, \n",
    "                    help='optimizer name')\n",
    "# parser.add_argument('--initmethod',\n",
    "#                     default='tcp://h0:22000',\n",
    "#                     type=str,\n",
    "#                     help='init method')\n",
    "parser.add_argument('--mu', \n",
    "                    default=0, \n",
    "                    type=float, \n",
    "                    help='mu parameter in fedprox')\n",
    "parser.add_argument('--savepath',\n",
    "                    default='./results/',\n",
    "                    type=str,\n",
    "                    help='directory to save exp results')\n",
    "parser.add_argument('--datapath',\n",
    "                    default='./data/',\n",
    "                    type=str,\n",
    "                    help='directory to load data')\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s - %(message)s', level=logging.INFO)\n",
    "logging.debug('This message should appear on the console')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "arg_defaults = {}\n",
    "for key in vars(args):\n",
    "    arg_defaults[key] = parser.get_default(key)\n",
    "arg_defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb567a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "LossResult = namedtuple(\"LossResult\", [\"sample_size\", \"loss_value\"])\n",
    "\n",
    "class client:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.optimizer = None\n",
    "        self.model=None\n",
    "        self.criterion = None\n",
    "        self.comm_rounds_x= []\n",
    "        self.acc_y = []\n",
    "    \n",
    "    algorithms = {\n",
    "            'fedavg': FedProx, # mu = 0\n",
    "            'fedprox': FedProx,\n",
    "            # 'scaffold': Scaffold,\n",
    "            'fednova': FedNova,\n",
    "            # 'fednova_vr':FedNovaVR,\n",
    "        }\n",
    "        \n",
    "    def run(self, init_run:bool, rank: int, size: int, round:int, opt:int):\n",
    "        # initiate experiments folder\n",
    "        save_path = args.savepath\n",
    "        folder_name = save_path+args.name\n",
    "\n",
    "        if rank == 0 and os.path.isdir(folder_name)==False and args.save: #first client\n",
    "            os.makedirs(folder_name)\n",
    "        # dist.barrier()\n",
    "\n",
    "        # initiate log files\n",
    "        tag = '{}/lr{:.3f}_bs{:d}_cp{:d}_a{:.2f}_e{}_r{}_n{}.csv'\n",
    "        saveFileName = tag.format(folder_name, args.lr, args.bs, args.localE, \n",
    "                                args.alpha, args.seed, round, size)\n",
    "        args.out_fname = saveFileName\n",
    "        with open(args.out_fname, 'w+') as f: #opens this file in results/default and writes the following print statement to it\n",
    "            print(\n",
    "                'TRAINING\\n'\n",
    "                'World-Size,{ws}\\n'\n",
    "                'Batch-Size,{bs}\\n'\n",
    "                'Round {rnd}'\n",
    "                'Epoch,itr,'\n",
    "                'Loss,avg:Loss, Prec@1, avg:Prec@1, val, time'.format(\n",
    "                    ws=args.size,\n",
    "                    bs=args.bs, rnd=round),\n",
    "                file=f)\n",
    "    \n",
    "\n",
    "        # seed for reproducibility\n",
    "        torch.manual_seed(args.seed)\n",
    "            \n",
    "        if init_run:\n",
    "            # load datasets\n",
    "            self.train_loader, self.test_loader, self.DataRatios = \\\n",
    "                util.partition_dataset(rank, size, args)\n",
    "            logging.debug(\"Worker rank {} local sample ratio {} \"\n",
    "                        \"local epoch length {}\"\n",
    "                        .format(rank, self.DataRatios[rank], len(self.train_loader)))\n",
    "            # define neural nets model, criterion, and optimizer\n",
    "            self.model = util.select_model(10, args).cpu()\n",
    "            self.criterion = nn.CrossEntropyLoss().cpu()\n",
    "\n",
    "            # select optimizer according to algorithm\n",
    "            \n",
    "            selected_opt = self.algorithms[args.optimizer] #fednova #instantiating an\n",
    "            \n",
    "            self.optimizer = selected_opt(self.model.parameters(),\n",
    "                                    lr=args.lr,\n",
    "                                    gmf=args.gmf,\n",
    "                                    mu=args.mu,\n",
    "                                    ratio=self.DataRatios[rank],\n",
    "                                    momentum=args.momentum,\n",
    "                                    nesterov = False,\n",
    "                                    weight_decay=1e-4)\n",
    "\n",
    "        best_test_accuracy = 0\n",
    "        \n",
    "\n",
    "        # Decide number of local updates per client\n",
    "        local_epochs = self.update_local_epochs(args.pattern, rank, round)\n",
    "        print('local_epochs: '+ str(local_epochs))\n",
    "\n",
    "        tau_i = local_epochs * len(self.train_loader)\n",
    "        logging.info(\"local epochs {} iterations {}\"\n",
    "                        .format(local_epochs, tau_i)) \n",
    "\n",
    "        # Decay learning rate according to round index\n",
    "        self.update_learning_rate(self.optimizer, round, args.lr)\n",
    "        # Clients locally train for several local epochs\n",
    "        \n",
    "               \n",
    "        for t in range(local_epochs): \n",
    "            sample_size, loss_value= self.train(self.model, self.criterion, self.optimizer, self.train_loader, t, rank)\n",
    "        \n",
    "        loss_result = LossResult(sample_size,loss_value)\n",
    "            \n",
    "            \n",
    "        \n",
    "    # # synchronize parameters\n",
    "    #     # dist.barrier()\n",
    "    #     comm_start = time.time()\n",
    "    #     optimizer.average()\n",
    "    #     # dist.barrier()\n",
    "    #     comm_end = time.time()\n",
    "    #     comm_time = comm_end - comm_start\n",
    "  \n",
    "    # evaluate test accuracy\n",
    "        test_acc = self.evaluate(self.model, self.test_loader)\n",
    "      \n",
    "        if test_acc > best_test_accuracy:\n",
    "            best_test_accuracy = test_acc\n",
    "    #### record metrics ####\n",
    "        logging.info(\"Round {} test accuracy {:.3f}\".format(round, test_acc))\n",
    "        with open(args.out_fname, '+a') as f:\n",
    "            print(' ayo metrics: {ep},{itr},{filler},{filler},'\n",
    "                    '{filler},{filler},'\n",
    "                    '{val:.4f}'\n",
    "                    .format(ep=round, itr=-1,\n",
    "                            filler=-1, val=test_acc), file=f)\n",
    "\n",
    "        logging.info(\"Worker {} best test accuracy {:.3f}\"\n",
    "                     .format(rank, best_test_accuracy))\n",
    "        \n",
    "        return self.optimizer, loss_result\n",
    "        \n",
    "        \n",
    "    def evaluate(self, model, test_loader) :\n",
    "        model.eval()\n",
    "        top1 = util.Meter(ptag='Loss')\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data = data.cpu()\n",
    "                target = target.cpu()\n",
    "                outputs = model(data)\n",
    "                loss1 = util.comp_accuracy(outputs, target)\n",
    "                top1.update(loss1[0].item(), data.size(0))\n",
    "\n",
    "        return top1.avg\n",
    "\n",
    "        \n",
    "    def train(self, model, criterion, optimizer, loader, epoch, rank):\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"classifier.6\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        losses = util.Meter(ptag='Loss')\n",
    "        top1 = util.Meter(ptag='Prec@1')\n",
    "\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            # data loading\n",
    "            \n",
    "            data = data.cpu()\n",
    "            target = target.cpu()\n",
    "\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient step\n",
    "            optimizer.step() #in fednova.py\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # write log files\n",
    "            train_acc = util.comp_accuracy(output, target)\n",
    "            \n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(train_acc[0].item(), data.size(0))\n",
    "\n",
    "            if batch_idx % args.print_freq == 0 and args.save:\n",
    "                logging.debug('epoch {} itr {}, '\n",
    "                            'rank {}, loss value {:.4f}, train accuracy {:.3f}'\n",
    "                            .format(epoch, batch_idx, rank, losses.avg, top1.avg))\n",
    "\n",
    "                with open(args.out_fname, '+a') as f:\n",
    "                    print('{ep},{itr},'\n",
    "                        '{loss.val:.4f},{loss.avg:.4f},'\n",
    "                        '{top1.val:.3f},{top1.avg:.3f},-1'\n",
    "                        .format(ep=epoch, itr=batch_idx,\n",
    "                                loss=losses, top1=top1), file=f)\n",
    "\n",
    "            with open(args.out_fname, '+a') as f:\n",
    "                print('{ep},{itr},'\n",
    "                    '{loss.val:.4f},{loss.avg:.4f},'\n",
    "                    '{top1.val:.3f},{top1.avg:.3f},-1'\n",
    "                    .format(ep=epoch, itr=batch_idx,\n",
    "                            loss=losses, top1=top1), file=f)\n",
    "        print('TEST LOSSES')\n",
    "        print(losses.avg)\n",
    "        \n",
    "        return len(loader), losses.avg\n",
    "\n",
    "    def update_local_epochs(self, pattern, rank: int, rnd: int):\n",
    "        if pattern == \"constant\":\n",
    "            return args.localE #basic case is what you input\n",
    "\n",
    "        if pattern == \"uniform_random\":\n",
    "            np.random.seed(2020+rank+rnd+args.seed)\n",
    "            return np.random.randint(low=2, high=args.localE, size=1)[0]\n",
    "\n",
    "\n",
    "    def update_learning_rate(self, optimizer, epoch, target_lr):\n",
    "        \"\"\"\n",
    "        1) Decay learning rate exponentially (epochs 30, 60, 80)\n",
    "        ** note: target_lr is the reference learning rate from which to scale down\n",
    "        \"\"\"\n",
    "        if epoch == int(args.rounds / 2):\n",
    "            lr = target_lr/10\n",
    "            logging.info('Updating learning rate to {}'.format(lr))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        if epoch == int(args.rounds * 0.75):\n",
    "            lr = target_lr/100\n",
    "            logging.info('Updating learning rate to {}'.format(lr))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3495cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "#server level\n",
    "\n",
    "def average_opt(opts_list, weight=0, tau_eff=0):\n",
    "  \n",
    "    #Loop through list of optimizers and sum up the tau_eff to get a global tau_eff\n",
    "    for opt in opts_list:\n",
    "        \n",
    "    # tau_eff\n",
    "    \n",
    "        if weight == 0:\n",
    "            weight = opt.ratio\n",
    "        if tau_eff == 0: \n",
    "            tau_eff==0\n",
    "            if opt.mu != 0:\n",
    "\n",
    "                tau_eff_cuda = torch.tensor(opt.local_steps*opt.ratio).cpu()\n",
    "            else:\n",
    "                print(opt.local_normalizing_vec)\n",
    "                tau_eff_cuda = torch.tensor(opt.local_normalizing_vec*opt.ratio).cpu()\n",
    "            # dist.all_reduce(tau_eff_cuda, op=dist.ReduceOp.SUM)\n",
    "            tau_eff += tau_eff_cuda.item() #Returns the value of this tensor as a standard Python number. This only works for tensors with one element.\n",
    "\n",
    "    #tau_eff is saved, will be passed onward\n",
    "    #loop from the optimizers again to get param\n",
    "    \n",
    "    full_param_list = [] #contains updated params from all optimizers\n",
    "    \n",
    "    for opt in opts_list:\n",
    "    \n",
    "        param_list = []\n",
    "        \n",
    "        for group in opt.param_groups:\n",
    "            \n",
    "            for p in group['params']:\n",
    "                param_state = opt.state[p]\n",
    "                scale = tau_eff/opt.local_normalizing_vec\n",
    "                if 'cum_grad' in param_state: #pytorch automatically does this for you\n",
    "                    param_state['cum_grad'].mul_(weight*scale)\n",
    "                    param_list.append(param_state['cum_grad'])\n",
    "        \n",
    "        #this part isnt so important since we dont use momentum buffers at the moment\n",
    "        for group in opt.param_groups:\n",
    "            lr = group['lr']\n",
    "            for p in group['params']:\n",
    "                param_state = opt.state[p]\n",
    "                \n",
    "                #optional\n",
    "                if opt.gmf != 0:\n",
    "                    if 'global_momentum_buffer' not in param_state:\n",
    "                        buf = param_state['global_momentum_buffer'] = torch.clone(param_state['cum_grad']).detach()\n",
    "                        buf.div_(lr)\n",
    "                    else:\n",
    "                        buf = param_state['global_momentum_buffer']\n",
    "                        buf.mul_(opt.gmf).add_(1/lr, param_state['cum_grad'])\n",
    "                    if 'old_init' in param_state:\n",
    "                        param_state['old_init'].sub_(lr, buf)\n",
    "                else:\n",
    "                    if 'old_init' in param_state:\n",
    "\n",
    "                        param_state['old_init'].sub_(param_state['cum_grad'])\n",
    "                \n",
    "                if 'old_init' and 'cum_grad' in param_state:\n",
    "                    p.data.copy_(param_state['old_init'])\n",
    "                    param_state['cum_grad'].zero_()\n",
    "\n",
    "            # Reinitialize momentum buffer\n",
    "                if 'momentum_buffer' in param_state:\n",
    "                    param_state['momentum_buffer'].zero_()       \n",
    "                    \n",
    "        opt.local_counter = 0\n",
    "        opt.local_normalizing_vec = 0\n",
    "        opt.local_steps = 0\n",
    "        \n",
    "        full_param_list.append(param_list)\n",
    "        \n",
    "    return full_param_list\n",
    "\n",
    "def load_state(opt, updated_params):\n",
    "        \n",
    "    param_index = 0\n",
    "    \n",
    "    for group in opt.param_groups:\n",
    "        for p in group['params']:\n",
    "            param_state = opt.state[p]\n",
    "            if 'cum_grad' in param_state: #pytorch automatically does this for you\n",
    "                param_state['cum_grad']= updated_params[param_index] \n",
    "                param_index+=1  \n",
    "    \n",
    "def weighted_loss_avg(results: List[LossResult]) -> float:\n",
    "    \"\"\"Aggregate loss evaluation results obtained from multiple clients.\"\"\"\n",
    "    num_total_evaluation_examples = sum([result.sample_size for result in results])\n",
    "    weighted_losses = [result.sample_size * result.loss_value for result in results]\n",
    "    return sum(weighted_losses) / num_total_evaluation_examples\n",
    "\n",
    "def plot_metrics(rounds, losses):\n",
    "        # print('rounds list {}'.format(rounds_x))\n",
    "        # print('losses list {}'.format(losses_y))\n",
    "\n",
    "        rounds_list = list(range(1,rounds+1))\n",
    "  \n",
    "        x = np.array(rounds_list)\n",
    "        y = np.array(losses)\n",
    "        # dataset = pd.DataFrame({'label': label, 'images': list(images)}, columns=['label', 'images'])\n",
    "        \n",
    "        df = pd.DataFrame({'round':x , 'loss': y})\n",
    "\n",
    "        # plt.plot(x,y, marker = 'o')\n",
    "        # plt.xticks(np.arange(min(x), max(x)+1, 1.0))\n",
    "        # plt.xlabel(\"Rounds\")\n",
    "        # plt.ylabel(\"Loss\")      \n",
    "    \n",
    "        fig = px.line(df, x=\"round\", y=\"loss\", title='Results')\n",
    "        fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0e6a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.5.6 64-bit ('venv-3.5.6')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/julia.ju/.pyenv/versions/venv-3.5.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "client1 = client()\n",
    "client2 = client()\n",
    "\n",
    "num_rounds = 4\n",
    "\n",
    "opt1 = 0\n",
    "opt2 = 0\n",
    "\n",
    "init_run = True\n",
    "\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for r in range(num_rounds):\n",
    "         \n",
    "    opt1, result_1 = client1.run(init_run, rank=args.rank, size=1, round=r, opt=opt1)\n",
    "    opt2, result_2 = client2.run(init_run, rank=args.rank, size=1, round=r, opt=opt2)\n",
    "    \n",
    "    opt_list = [opt1, opt2]\n",
    "    all_results = [result_1,result_2]\n",
    "\n",
    "    updated_params = average_opt(opt_list)\n",
    "    \n",
    "    load_state(opt1, updated_params[0])\n",
    "    load_state(opt2, updated_params[1])\n",
    "    \n",
    "    ## need sample lengths + loss values \n",
    "    \n",
    "    weighted_avg = weighted_loss_avg(all_results)\n",
    "    loss_list.append(weighted_avg)\n",
    "\n",
    "    \n",
    "    print('-----ROUND COMPLETED-----')    \n",
    "    ## add a flag that will go to false when the first loop ends, so that it doesn't need to \n",
    "    init_run= False\n",
    "    \n",
    "    \n",
    "\n",
    "plot_metrics(num_rounds, loss_list)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa53ff979890fe2ee43ebe55261cf606546aca0d0d9789e51d7aa3559571d2be"
  },
  "kernelspec": {
   "display_name": "venv-3.5.6",
   "language": "python",
   "name": "venv-3.5.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
