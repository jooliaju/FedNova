{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c3612a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6428e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import math\n",
    "from math import ceil\n",
    "from random import Random\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data.distributed\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import Process\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "\n",
    "from distoptim import FedProx, FedNova\n",
    "import util_v4 as util\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NIID': False,\n",
       " 'alpha': 0.2,\n",
       " 'backend': 'nccl',\n",
       " 'bs': 32,\n",
       " 'datapath': './data/',\n",
       " 'gmf': 0,\n",
       " 'localE': 2,\n",
       " 'lr': 0.1,\n",
       " 'model': 'VGG',\n",
       " 'momentum': 0.0,\n",
       " 'mu': 0,\n",
       " 'name': 'default',\n",
       " 'optimizer': 'fednova',\n",
       " 'p': False,\n",
       " 'pattern': 'constant',\n",
       " 'print_freq': 100,\n",
       " 'rank': 0,\n",
       " 'rounds': 4,\n",
       " 'save': True,\n",
       " 'savepath': './results/',\n",
       " 'seed': 1,\n",
       " 'size': 1}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='CIFAR-10 baseline')\n",
    "parser.add_argument('--name','-n', \n",
    "                    default=\"default\", \n",
    "                    type=str, \n",
    "                    help='experiment name, used for saving results')\n",
    "parser.add_argument('--backend',\n",
    "                    default=\"nccl\",\n",
    "                    type=str,\n",
    "                    help='background name')\n",
    "parser.add_argument('--model', \n",
    "                    default=\"VGG\", #default: res\n",
    "                    type=str, \n",
    "                    help='neural network model')\n",
    "parser.add_argument('--alpha', \n",
    "                    default=0.2, \n",
    "                    type=float, \n",
    "                    help='control the non-iidness of dataset')\n",
    "parser.add_argument('--gmf', \n",
    "                    default=0, \n",
    "                    type=float, \n",
    "                    help='global (server) momentum factor')\n",
    "parser.add_argument('--lr', \n",
    "                    default=0.1, \n",
    "                    type=float, \n",
    "                    help='client learning rate')\n",
    "parser.add_argument('--momentum', \n",
    "                    default=0.0, \n",
    "                    type=float, \n",
    "                    help='local (client) momentum factor')\n",
    "parser.add_argument('--bs', \n",
    "                    default=16, \n",
    "                    type=int, \n",
    "                    help='batch size on each worker/client')\n",
    "parser.add_argument('--rounds', \n",
    "                    default=4, \n",
    "                    type=int, \n",
    "                    help='total coommunication rounds')\n",
    "parser.add_argument('--localE', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='number of local epochs')\n",
    "parser.add_argument('--print_freq', \n",
    "                    default=100, \n",
    "                    type=int, \n",
    "                    help='print info frequency')\n",
    "parser.add_argument('--size', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='number of local workers')\n",
    "parser.add_argument('--rank', \n",
    "                    default=0, \n",
    "                    type=int, \n",
    "                    help='the rank of worker')\n",
    "parser.add_argument('--seed', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='random seed')\n",
    "parser.add_argument('--save', '-s', \n",
    "                    default=True, \n",
    "                    action='store_true', \n",
    "                    help='whether save the training results')\n",
    "parser.add_argument('--p', '-p', \n",
    "                    action='store_true', \n",
    "                    help='whether the dataset is partitioned or not')\n",
    "parser.add_argument('--NIID',\n",
    "                    action='store_true',\n",
    "                    help='whether the dataset is non-iid or not')\n",
    "parser.add_argument('--pattern',\n",
    "                    default='constant',\n",
    "                    type=str, \n",
    "                    help='pattern of local steps')\n",
    "parser.add_argument('--optimizer', \n",
    "                    default='fednova',  ##default is 'local'\n",
    "                    type=str, \n",
    "                    help='optimizer name')\n",
    "# parser.add_argument('--initmethod',\n",
    "#                     default='tcp://h0:22000',\n",
    "#                     type=str,\n",
    "#                     help='init method')\n",
    "parser.add_argument('--mu', \n",
    "                    default=0, \n",
    "                    type=float, \n",
    "                    help='mu parameter in fedprox')\n",
    "parser.add_argument('--savepath',\n",
    "                    default='./results/',\n",
    "                    type=str,\n",
    "                    help='directory to save exp results')\n",
    "parser.add_argument('--datapath',\n",
    "                    default='./data/',\n",
    "                    type=str,\n",
    "                    help='directory to load data')\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s - %(message)s', level=logging.INFO)\n",
    "logging.debug('This message should appear on the console')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "arg_defaults = {}\n",
    "for key in vars(args):\n",
    "    arg_defaults[key] = parser.get_default(key)\n",
    "arg_defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb567a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class client:\n",
    "        \n",
    "    def run(self, rank: int, size: int):\n",
    "        # initiate experiments folder\n",
    "        save_path = args.savepath\n",
    "        folder_name = save_path+args.name\n",
    "\n",
    "        if rank == 0 and os.path.isdir(folder_name)==False and args.save: #first client\n",
    "            os.makedirs(folder_name)\n",
    "            print('made!')\n",
    "        # dist.barrier()\n",
    "\n",
    "        # initiate log files\n",
    "        tag = '{}/lr{:.3f}_bs{:d}_cp{:d}_a{:.2f}_e{}_r{}_n{}.csv'\n",
    "        saveFileName = tag.format(folder_name, args.lr, args.bs, args.localE, \n",
    "                                args.alpha, args.seed, rank, size)\n",
    "        args.out_fname = saveFileName\n",
    "        with open(args.out_fname, 'w+') as f: #opens this file in results/default and writes the following print statement to it\n",
    "            print(\n",
    "                'BEGIN-TRAINING\\n'\n",
    "                'World-Size,{ws}\\n'\n",
    "                'Batch-Size,{bs}\\n'\n",
    "                'Epoch,itr,'\n",
    "                'Loss,avg:Loss,Prec@1,avg:Prec@1,val,time'.format(\n",
    "                    ws=args.size,\n",
    "                    bs=args.bs),\n",
    "                file=f)\n",
    "\n",
    "\n",
    "        # seed for reproducibility\n",
    "        torch.manual_seed(args.seed)\n",
    "        # torch.cuda.manual_seed(args.seed)\n",
    "        # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "        # load datasets\n",
    "        train_loader, test_loader, DataRatios = \\\n",
    "            util.partition_dataset(rank, size, args)\n",
    "        logging.debug(\"Worker id {} local sample ratio {} \"\n",
    "                      \"local epoch length {}\"\n",
    "                      .format(rank, DataRatios[rank], len(train_loader)))\n",
    "\n",
    "        # define neural nets model, criterion, and optimizer\n",
    "        model = util.select_model(10, args).cpu()\n",
    "        criterion = nn.CrossEntropyLoss().cpu()\n",
    "\n",
    "        # select optimizer according to algorithm\n",
    "        algorithms = {\n",
    "            'fedavg': FedProx, # mu = 0\n",
    "            'fedprox': FedProx,\n",
    "            # 'scaffold': Scaffold,\n",
    "            'fednova': FedNova,\n",
    "            # 'fednova_vr':FedNovaVR,\n",
    "        }\n",
    "        selected_opt = algorithms[args.optimizer]\n",
    "\n",
    "        optimizer = selected_opt(model.parameters(),\n",
    "                                 lr=args.lr,\n",
    "                                 gmf=args.gmf,\n",
    "                                 mu=args.mu,\n",
    "                                 ratio=DataRatios[rank],\n",
    "                                 momentum=args.momentum,\n",
    "                                 nesterov = False,\n",
    "                                 weight_decay=1e-4)\n",
    "\n",
    "        best_test_accuracy = 0\n",
    "\n",
    "        #iterating through rounds now\n",
    "        for rnd in range(args.rounds): \n",
    "        # Decide number of local updates per client\n",
    "            local_epochs = self.update_local_epochs(args.pattern, rank, rnd)\n",
    "            tau_i = local_epochs * len(train_loader)\n",
    "            logging.info(\"local epochs {} iterations {}\"\n",
    "                          .format(local_epochs, tau_i))\n",
    "\n",
    "            # Decay learning rate according to round index\n",
    "            self.update_learning_rate(optimizer, rnd, args.lr)\n",
    "            # Clients locally train for several local epochs\n",
    "            for t in range(local_epochs):\n",
    "                self.train(model, criterion, optimizer, train_loader, t, rank)\n",
    "            \n",
    "        # synchronize parameters\n",
    "            # dist.barrier()\n",
    "            comm_start = time.time()\n",
    "            optimizer.average()\n",
    "            # dist.barrier()\n",
    "            comm_end = time.time()\n",
    "            comm_time = comm_end - comm_start\n",
    "            \n",
    "        # evaluate test accuracy\n",
    "            test_acc = self.evaluate(model, test_loader)\n",
    "            if test_acc > best_test_accuracy:\n",
    "                best_test_accuracy = test_acc\n",
    "            \n",
    "        # record metrics\n",
    "            logging.info(\"Round {} test accuracy {:.3f} time {:.3f}\".format(rnd, test_acc, comm_time))\n",
    "            with open(args.out_fname, '+a') as f:\n",
    "                print('{ep},{itr},{filler},{filler},'\n",
    "                      '{filler},{filler},'\n",
    "                      '{val:.4f},{time:.4f}'\n",
    "                      .format(ep=rnd, itr=-1,\n",
    "                              filler=-1, val=test_acc, time=comm_time), file=f)\n",
    "\n",
    "        logging.info(\"Worker {} best test accuracy {:.3f}\"\n",
    "                     .format(rank, best_test_accuracy))\n",
    "\n",
    "    def evaluate(model, test_loader):\n",
    "        model.eval()\n",
    "        top1 = util.Meter(ptag='Acc')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data = data.cpu()\n",
    "                target = target.cpu()\n",
    "                outputs = model(data)\n",
    "                acc1 = util.comp_accuracy(outputs, target)\n",
    "                top1.update(acc1[0].item(), data.size(0))\n",
    "\n",
    "        return top1.avg\n",
    "\n",
    "    \n",
    "        \n",
    "    def train(self, model, criterion, optimizer, loader, epoch, rank):\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"classifier.6\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        losses = util.Meter(ptag='Loss')\n",
    "        top1 = util.Meter(ptag='Prec@1')\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            # data loading\n",
    "            data = data.cpu()\n",
    "            target = target.cpu()\n",
    "\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # write log files\n",
    "            train_acc = util.comp_accuracy(output, target)\n",
    "            \n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(train_acc[0].item(), data.size(0))\n",
    "\n",
    "            if batch_idx % args.print_freq == 0 and args.save:\n",
    "                logging.debug('epoch {} itr {}, '\n",
    "                            'rank {}, loss value {:.4f}, train accuracy {:.3f}'\n",
    "                            .format(epoch, batch_idx, rank, losses.avg, top1.avg))\n",
    "\n",
    "                with open(args.out_fname, '+a') as f:\n",
    "                    print('{ep},{itr},'\n",
    "                        '{loss.val:.4f},{loss.avg:.4f},'\n",
    "                        '{top1.val:.3f},{top1.avg:.3f},-1'\n",
    "                        .format(ep=epoch, itr=batch_idx,\n",
    "                                loss=losses, top1=top1), file=f)\n",
    "\n",
    "            with open(args.out_fname, '+a') as f:\n",
    "                print('{ep},{itr},'\n",
    "                    '{loss.val:.4f},{loss.avg:.4f},'\n",
    "                    '{top1.val:.3f},{top1.avg:.3f},-1'\n",
    "                    .format(ep=epoch, itr=batch_idx,\n",
    "                            loss=losses, top1=top1), file=f)\n",
    "\n",
    "\n",
    "    def update_local_epochs(self, pattern, rank: int, rnd: int):\n",
    "        if pattern == \"constant\":\n",
    "            return args.localE\n",
    "\n",
    "        if pattern == \"uniform_random\":\n",
    "            np.random.seed(2020+rank+rnd+args.seed)\n",
    "            return np.random.randint(low=2, high=args.localE, size=1)[0]\n",
    "\n",
    "\n",
    "    def update_learning_rate(self, optimizer, epoch, target_lr):\n",
    "        \"\"\"\n",
    "        1) Decay learning rate exponentially (epochs 30, 60, 80)\n",
    "        ** note: target_lr is the reference learning rate from which to scale down\n",
    "        \"\"\"\n",
    "        if epoch == int(args.rounds / 2):\n",
    "            lr = target_lr/10\n",
    "            logging.info('Updating learning rate to {}'.format(lr))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        if epoch == int(args.rounds * 0.75):\n",
    "            lr = target_lr/100\n",
    "            logging.info('Updating learning rate to {}'.format(lr))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d2d6573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "==> load train data\n",
      "Files already downloaded and verified\n",
      "==> load test data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - local epochs 2 iterations 1564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_rounds=1\n",
    "\n",
    "for rnd in range(n_rounds):\n",
    "    client1 = client()\n",
    "    client2 = client()\n",
    "    \n",
    "    print(args.rank)\n",
    "\n",
    "    client1_results = client1.run(rank=args.rank, size=2)\n",
    "    # client2_results = client2.run(rank=args.rank, size=2)\n",
    "\n",
    "    # aggregated_results = aggr([client1_results, client2_results])\n",
    "    # client1.load_state(aggregated_results)\n",
    "    # client2.load_state(aggregated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477fe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank = args.rank\n",
    "# size = args.size\n",
    "# print(rank)\n",
    "# init_processes(rank, size, run)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa53ff979890fe2ee43ebe55261cf606546aca0d0d9789e51d7aa3559571d2be"
  },
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('venv-3.5.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
