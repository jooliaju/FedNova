{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c3612a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6428e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import math\n",
    "from math import ceil\n",
    "from random import Random\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data.distributed\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import Process\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "\n",
    "from distoptim import FedProx, FedNova\n",
    "import util_v4 as util\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5821ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NIID': False,\n",
       " 'alpha': 0.2,\n",
       " 'backend': 'nccl',\n",
       " 'bs': 32,\n",
       " 'datapath': './data/',\n",
       " 'gmf': 0,\n",
       " 'localE': 1,\n",
       " 'lr': 0.1,\n",
       " 'model': 'VGG',\n",
       " 'momentum': 0.0,\n",
       " 'mu': 0,\n",
       " 'name': 'default',\n",
       " 'optimizer': 'fednova',\n",
       " 'p': False,\n",
       " 'pattern': 'constant',\n",
       " 'print_freq': 100,\n",
       " 'rank': 0,\n",
       " 'rounds': 4,\n",
       " 'save': True,\n",
       " 'savepath': './results/',\n",
       " 'seed': 1,\n",
       " 'size': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='CIFAR-10 baseline')\n",
    "parser.add_argument('--name','-n', \n",
    "                    default=\"default\", \n",
    "                    type=str, \n",
    "                    help='experiment name, used for saving results')\n",
    "parser.add_argument('--backend',\n",
    "                    default=\"nccl\",\n",
    "                    type=str,\n",
    "                    help='background name')\n",
    "parser.add_argument('--model', \n",
    "                    default=\"VGG\", #default: res\n",
    "                    type=str, \n",
    "                    help='neural network model')\n",
    "parser.add_argument('--alpha', \n",
    "                    default=0.2, \n",
    "                    type=float, \n",
    "                    help='control the non-iidness of dataset')\n",
    "parser.add_argument('--gmf', \n",
    "                    default=0, \n",
    "                    type=float, \n",
    "                    help='global (server) momentum factor')\n",
    "parser.add_argument('--lr', \n",
    "                    default=0.1, \n",
    "                    type=float, \n",
    "                    help='client learning rate')\n",
    "parser.add_argument('--momentum', \n",
    "                    default=0.0, \n",
    "                    type=float, \n",
    "                    help='local (client) momentum factor')\n",
    "parser.add_argument('--bs', \n",
    "                    default=32, \n",
    "                    type=int, \n",
    "                    help='batch size on each worker/client')\n",
    "parser.add_argument('--rounds', \n",
    "                    default=4, \n",
    "                    type=int, \n",
    "                    help='total coommunication rounds')\n",
    "parser.add_argument('--localE', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='number of local epochs')\n",
    "parser.add_argument('--print_freq', \n",
    "                    default=100, \n",
    "                    type=int, \n",
    "                    help='print info frequency')\n",
    "parser.add_argument('--size', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='number of local workers')\n",
    "parser.add_argument('--rank', \n",
    "                    default=0, \n",
    "                    type=int, \n",
    "                    help='the rank of worker')\n",
    "parser.add_argument('--seed', \n",
    "                    default=1, \n",
    "                    type=int, \n",
    "                    help='random seed')\n",
    "parser.add_argument('--save', '-s', \n",
    "                    default=True, \n",
    "                    action='store_true', \n",
    "                    help='whether save the training results')\n",
    "parser.add_argument('--p', '-p', \n",
    "                    action='store_true', \n",
    "                    help='whether the dataset is partitioned or not')\n",
    "parser.add_argument('--NIID',\n",
    "                    \n",
    "                    action='store_true',\n",
    "                    help='whether the dataset is non-iid or not')\n",
    "parser.add_argument('--pattern',\n",
    "                    default='constant',\n",
    "                    type=str, \n",
    "                    help='pattern of local steps')\n",
    "parser.add_argument('--optimizer', \n",
    "                    default='fednova',  ##default is 'local'\n",
    "                    type=str, \n",
    "                    help='optimizer name')\n",
    "# parser.add_argument('--initmethod',\n",
    "#                     default='tcp://h0:22000',\n",
    "#                     type=str,\n",
    "#                     help='init method')\n",
    "parser.add_argument('--mu', \n",
    "                    default=0, \n",
    "                    type=float, \n",
    "                    help='mu parameter in fedprox')\n",
    "parser.add_argument('--savepath',\n",
    "                    default='./results/',\n",
    "                    type=str,\n",
    "                    help='directory to save exp results')\n",
    "parser.add_argument('--datapath',\n",
    "                    default='./data/',\n",
    "                    type=str,\n",
    "                    help='directory to load data')\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s - %(message)s', level=logging.INFO)\n",
    "logging.debug('This message should appear on the console')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "arg_defaults = {}\n",
    "for key in vars(args):\n",
    "    arg_defaults[key] = parser.get_default(key)\n",
    "arg_defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4eb567a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class client:\n",
    "    \n",
    "    algorithms = {\n",
    "            'fedavg': FedProx, # mu = 0\n",
    "            'fedprox': FedProx,\n",
    "            # 'scaffold': Scaffold,\n",
    "            'fednova': FedNova,\n",
    "            # 'fednova_vr':FedNovaVR,\n",
    "        }\n",
    "        \n",
    "    def run(self, init_run:bool, rank: int, size: int, rnd:int, opt:int):\n",
    "        # initiate experiments folder\n",
    "        save_path = args.savepath\n",
    "        folder_name = save_path+args.name\n",
    "\n",
    "        if rank == 0 and os.path.isdir(folder_name)==False and args.save: #first client\n",
    "            os.makedirs(folder_name)\n",
    "            print('made!')\n",
    "        # dist.barrier()\n",
    "\n",
    "        # initiate log files\n",
    "        tag = '{}/lr{:.3f}_bs{:d}_cp{:d}_a{:.2f}_e{}_r{}_n{}.csv'\n",
    "        saveFileName = tag.format(folder_name, args.lr, args.bs, args.localE, \n",
    "                                args.alpha, args.seed, rank, size)\n",
    "        args.out_fname = saveFileName\n",
    "        with open(args.out_fname, 'w+') as f: #opens this file in results/default and writes the following print statement to it\n",
    "            print(\n",
    "                'BEGIN-TRAINING\\n'\n",
    "                'World-Size,{ws}\\n'\n",
    "                'Batch-Size,{bs}\\n'\n",
    "                'Epoch,itr,'\n",
    "                'Loss,avg:Loss,Prec@1,avg:Prec@1,val,time'.format(\n",
    "                    ws=args.size,\n",
    "                    bs=args.bs),\n",
    "                file=f)\n",
    "            \n",
    "\n",
    "\n",
    "        # seed for reproducibility\n",
    "        torch.manual_seed(args.seed)\n",
    "        # torch.cuda.manual_seed(args.seed)\n",
    "        # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "        # load datasets\n",
    "        \n",
    "        train_loader, test_loader, DataRatios = \\\n",
    "            util.partition_dataset(rank, size, args)\n",
    "        logging.debug(\"Worker id {} local sample ratio {} \"\n",
    "                      \"local epoch length {}\"\n",
    "                      .format(rank, DataRatios[rank], len(train_loader)))\n",
    "\n",
    "        # define neural nets model, criterion, and optimizer\n",
    "        model = util.select_model(10, args).cpu()\n",
    "        criterion = nn.CrossEntropyLoss().cpu()\n",
    "\n",
    "        # select optimizer according to algorithm\n",
    "        \n",
    "        selected_opt = self.algorithms[args.optimizer] #fednova #instantiating an\n",
    "        \n",
    "        optimizer = selected_opt(model.parameters(),\n",
    "                                 lr=args.lr,\n",
    "                                 gmf=args.gmf,\n",
    "                                 mu=args.mu,\n",
    "                                 ratio=DataRatios[rank],\n",
    "                                 momentum=args.momentum,\n",
    "                                 nesterov = False,\n",
    "                                 weight_decay=1e-4)\n",
    "\n",
    "        best_test_accuracy = 0\n",
    "\n",
    "        # Decide number of local updates per client\n",
    "        local_epochs = self.update_local_epochs(args.pattern, rank, rnd)\n",
    "        print('local_epochs: '+ str(local_epochs))\n",
    "\n",
    "        tau_i = local_epochs * len(train_loader)\n",
    "        logging.info(\"local epochs {} iterations {}\"\n",
    "                        .format(local_epochs, tau_i)) \n",
    "        print('train loader: '+ str(len(train_loader)))\n",
    "        print('RATIO: '+ str(optimizer.ratio))\n",
    "\n",
    "        # Decay learning rate according to round index\n",
    "        self.update_learning_rate(optimizer, rnd, args.lr)\n",
    "        # Clients locally train for several local epochs\n",
    "        for t in range(local_epochs):\n",
    "            self.train(model, criterion, optimizer, train_loader, t, rank)\n",
    "        \n",
    "    # # synchronize parameters\n",
    "    #     # dist.barrier()\n",
    "    #     comm_start = time.time()\n",
    "    #     optimizer.average()\n",
    "    #     # dist.barrier()\n",
    "    #     comm_end = time.time()\n",
    "    #     comm_time = comm_end - comm_start\n",
    "        \n",
    "    # # evaluate test accuracy\n",
    "    #     test_acc = self.evaluate(model, test_loader)\n",
    "    #     if test_acc > best_test_accuracy:\n",
    "    #         best_test_accuracy = test_acc\n",
    "        \n",
    "    # # record metrics\n",
    "    #     logging.info(\"Round {} test accuracy {:.3f} time {:.3f}\".format(rnd, test_acc, comm_time))\n",
    "    #     with open(args.out_fname, '+a') as f:\n",
    "    #         print('{ep},{itr},{filler},{filler},'\n",
    "    #                 '{filler},{filler},'\n",
    "    #                 '{val:.4f},{time:.4f}'\n",
    "    #                 .format(ep=rnd, itr=-1,\n",
    "    #                         filler=-1, val=test_acc, time=comm_time), file=f)\n",
    "\n",
    "    #     logging.info(\"Worker {} best test accuracy {:.3f}\"\n",
    "    #                  .format(rank, best_test_accuracy))\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "    def evaluate(model, test_loader) :\n",
    "        model.eval()\n",
    "        top1 = util.Meter(ptag='Acc')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data = data.cpu()\n",
    "                target = target.cpu()\n",
    "                outputs = model(data)\n",
    "                acc1 = util.comp_accuracy(outputs, target)\n",
    "                top1.update(acc1[0].item(), data.size(0))\n",
    "\n",
    "        return top1.avg\n",
    "\n",
    "        \n",
    "    def train(self, model, criterion, optimizer, loader, epoch, rank):\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"classifier.6\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        losses = util.Meter(ptag='Loss')\n",
    "        top1 = util.Meter(ptag='Prec@1')\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            # data loading\n",
    "            data = data.cpu()\n",
    "            target = target.cpu()\n",
    "\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient step\n",
    "            optimizer.step() #in fednova.py\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # write log files\n",
    "            train_acc = util.comp_accuracy(output, target)\n",
    "            \n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(train_acc[0].item(), data.size(0))\n",
    "\n",
    "            if batch_idx % args.print_freq == 0 and args.save:\n",
    "                logging.debug('epoch {} itr {}, '\n",
    "                            'rank {}, loss value {:.4f}, train accuracy {:.3f}'\n",
    "                            .format(epoch, batch_idx, rank, losses.avg, top1.avg))\n",
    "\n",
    "                with open(args.out_fname, '+a') as f:\n",
    "                    print('{ep},{itr},'\n",
    "                        '{loss.val:.4f},{loss.avg:.4f},'\n",
    "                        '{top1.val:.3f},{top1.avg:.3f},-1'\n",
    "                        .format(ep=epoch, itr=batch_idx,\n",
    "                                loss=losses, top1=top1), file=f)\n",
    "\n",
    "            with open(args.out_fname, '+a') as f:\n",
    "                print('{ep},{itr},'\n",
    "                    '{loss.val:.4f},{loss.avg:.4f},'\n",
    "                    '{top1.val:.3f},{top1.avg:.3f},-1'\n",
    "                    .format(ep=epoch, itr=batch_idx,\n",
    "                            loss=losses, top1=top1), file=f)\n",
    "\n",
    "\n",
    "    def update_local_epochs(self, pattern, rank: int, rnd: int):\n",
    "        if pattern == \"constant\":\n",
    "            return args.localE #basic case is what you input\n",
    "\n",
    "        if pattern == \"uniform_random\":\n",
    "            np.random.seed(2020+rank+rnd+args.seed)\n",
    "            return np.random.randint(low=2, high=args.localE, size=1)[0]\n",
    "\n",
    "\n",
    "    def update_learning_rate(self, optimizer, epoch, target_lr):\n",
    "        \"\"\"\n",
    "        1) Decay learning rate exponentially (epochs 30, 60, 80)\n",
    "        ** note: target_lr is the reference learning rate from which to scale down\n",
    "        \"\"\"\n",
    "        if epoch == int(args.rounds / 2):\n",
    "            lr = target_lr/10\n",
    "            logging.info('Updating learning rate to {}'.format(lr))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        if epoch == int(args.rounds * 0.75):\n",
    "            lr = target_lr/100\n",
    "            logging.info('Updating learning rate to {}'.format(lr))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e982059",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-094cacd51255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mparam_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt1' is not defined"
     ]
    }
   ],
   "source": [
    "# print(opt1.param_groups[0]['params'])\n",
    "# print(opt1.state[0])\n",
    "tau_eff =1\n",
    "weight=1\n",
    "\n",
    "param_list = []\n",
    "for group in opt1.param_groups:\n",
    "    print(group)\n",
    "    for p in group['params']:\n",
    "        param_state = opt1.state[p]\n",
    "        scale = tau_eff/opt1.local_normalizing_vec\n",
    "        \n",
    "        if 'cum_grad' in param_state:\n",
    "            param_state['cum_grad'].mul_(weight*scale)\n",
    "            param_list.append(param_state['cum_grad'])\n",
    "            \n",
    "print(param_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f3495cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#server level\n",
    "# def average(opt, weight=0, tau_eff=0):\n",
    "\n",
    "def average_opt(lst_opts,weight=0, tau_eff=0):\n",
    "    ## opt = self\n",
    "    # tau_eff=0\n",
    "    \n",
    "    \n",
    "    #Loop through list of optimizers and sum up the tau_eff to get a global tau_eff\n",
    "    for opt in lst_opts:\n",
    "        \n",
    "    # tau_eff\n",
    "    \n",
    "        opt.local_normalizing_vec = 1\n",
    "\n",
    "        if weight == 0:\n",
    "            weight = opt.ratio\n",
    "        if tau_eff == 0: \n",
    "            tau_eff==0\n",
    "            if opt.mu != 0:\n",
    "\n",
    "                tau_eff_cuda = torch.tensor(opt.local_steps*opt.ratio).cpu()\n",
    "            else:\n",
    "                print(opt.local_normalizing_vec)\n",
    "                tau_eff_cuda = torch.tensor(opt.local_normalizing_vec*opt.ratio).cpu()\n",
    "            # dist.all_reduce(tau_eff_cuda, op=dist.ReduceOp.SUM)\n",
    "            tau_eff += tau_eff_cuda.item() #Returns the value of this tensor as a standard Python number. This only works for tensors with one element.\n",
    "\n",
    "    #tau_eff is saved, will be passed onward\n",
    "     \n",
    "    #loop from the optimizers again to get param\n",
    "    for opt in lst_opts:\n",
    "        \n",
    "            \n",
    "        param_list = []\n",
    "        \n",
    "        for group in opt.param_groups:\n",
    "            \n",
    "            for p in group['params']:\n",
    "                param_state = opt.state[p]\n",
    "                scale = tau_eff/opt.local_normalizing_vec\n",
    "                if 'cum_grad' in param_state: #pytorch automatically does this for you\n",
    "                    param_state['cum_grad'].mul_(weight*scale)\n",
    "                    param_list.append(param_state['cum_grad'])\n",
    "                \n",
    "        #add param list together from all optimizers\n",
    "        #or dont add, just return list\n",
    "        \n",
    "        #return sum\n",
    "        \n",
    "        \n",
    "        # communicate(param_list, dist.all_reduce)\n",
    "        \n",
    "        #this part isnt so important since we dont use momentum buffers at the moment\n",
    "        for group in opt.param_groups:\n",
    "            lr = group['lr']\n",
    "            for p in group['params']:\n",
    "                param_state = opt.state[p]\n",
    "                \n",
    "                #optional\n",
    "                if opt.gmf != 0:\n",
    "                    if 'global_momentum_buffer' not in param_state:\n",
    "                        buf = param_state['global_momentum_buffer'] = torch.clone(param_state['cum_grad']).detach()\n",
    "                        buf.div_(lr)\n",
    "                    else:\n",
    "                        buf = param_state['global_momentum_buffer']\n",
    "                        buf.mul_(opt.gmf).add_(1/lr, param_state['cum_grad'])\n",
    "                    if 'old_init' in param_state:\n",
    "                        param_state['old_init'].sub_(lr, buf)\n",
    "                else:\n",
    "                    if 'old_init' in param_state:\n",
    "\n",
    "                        param_state['old_init'].sub_(param_state['cum_grad'])\n",
    "                \n",
    "                if 'old_init' and 'cum_grad' in param_state:\n",
    "                    p.data.copy_(param_state['old_init'])\n",
    "                    param_state['cum_grad'].zero_()\n",
    "\n",
    "            # Reinitialize momentum buffer\n",
    "                if 'momentum_buffer' in param_state:\n",
    "                    param_state['momentum_buffer'].zero_()       \n",
    "                    \n",
    "        opt.local_counter = 0\n",
    "        opt.local_normalizing_vec = 0\n",
    "        opt.local_steps = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ce0e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT 1\n",
      "==> load train data\n",
      "Files already downloaded and verified\n",
      "RATIOOOO: [0.05]\n",
      "yooooooo\n",
      "==> load test data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - local epochs 1 iterations 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay this is returning a vgg11 model\n",
      "local_epochs: 1\n",
      "train loader: 79\n",
      "RATIO: 0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b29b17982d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPT 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mopt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPT 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-fce19ad1f1b6>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, init_run, rank, size, rnd, opt)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Clients locally train for several local epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# # synchronize parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-fce19ad1f1b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, loader, epoch, rank)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/envs/venv-3.5.6/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/FedNova/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/envs/venv-3.5.6/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/envs/venv-3.5.6/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/envs/venv-3.5.6/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/envs/venv-3.5.6/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.6/envs/venv-3.5.6/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 350\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "client1 = client()\n",
    "client2 = client()\n",
    "num_rounds = 1\n",
    "\n",
    "opt1 = 0\n",
    "opt2 = 0\n",
    "\n",
    "init_run = True\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    \n",
    "    print('OPT 1')\n",
    "    opt1 = client1.run(init_run, rank=args.rank, size=1, rnd=0, opt=opt1)\n",
    "\n",
    "    print('OPT 2')\n",
    "    opt2 = client2.run(init_run, rank=args.rank, size=1, rnd=0, opt=opt2)\n",
    "    lst_opts = [opt1, opt2]\n",
    "\n",
    "    # client1.evaluate_round(rnd)\n",
    "    # client2.evaluate_round(rnd)\n",
    "    # client1.evaluate(rnd)\n",
    "    # client2.evaluate_round(rnd)\n",
    "\n",
    "    avg_opt = average_opt(lst_opts)\n",
    "    \n",
    "    # print('success')\n",
    "\n",
    "## make another function that will upload the param lists to the optimizers\n",
    "    # opt1._load_state(avg_opt)\n",
    "    # opt2._load_state(avg_opt)\n",
    "    \n",
    "    ## add a flag that will go to false when the first loop ends, so that it doesn't need to \n",
    "    init_run= False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65b35065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "lst_opts = [opt1, opt2]\n",
    "avg_opt = average_opt(lst_opts)\n",
    "\n",
    "# client1.evaluate_round(rnd)\n",
    "# client2.evaluate_round(rnd)\n",
    "# client1.evaluate(rnd)\n",
    "# client2.evaluate_round(rnd)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d0b3194f1de6a6c15b77cb1179360b7dec34e35e24ac8a46b515d33cd656b5d"
  },
  "kernelspec": {
   "display_name": "Python 3.5.6 ('FedNova-5oxzwFFS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
